{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "# Feature Extraction with BERT (Windows, CUDA)\n",
=======
    "# Feature Extraction with BERT\n",
>>>>>>> c8392bb066f907fa151a0a2ce9c1eca022ae90cc
    "Il presente Notebook mostra come effettuare l'estrazione delle Feature dal Training e dal Test Set mediante BERT. Attenzione! Il seguente codice risulta differenziato rispetto a quello dei classificatori poiché, per ragioni di efficienza, è stato eseguito su una GPU (Nvidia GeForce RTX 3060) mediante l'ausilio di CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo De Cesaris\\AppData\\Local\\Temp\\ipykernel_6052\\1961802347.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "e:\\anaconda3\\envs\\DLProjectCUDA\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import cuda\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set.shape: (30577, 2)\n",
      "test_set.shape: (63842, 2)\n",
      "other_set.shape: (89004, 2)\n"
     ]
    }
   ],
   "source": [
    "# Caricamento dei Dataset\n",
    "training_set = pd.read_csv(\"./../../datasets/training_set.csv\")\n",
    "test_data = pd.read_csv(\"./../../datasets/test_set.csv\")\n",
    "\n",
    "test_data.dropna(inplace=True)\n",
    "\n",
    "test_set = test_data[test_data['toxic'] != -1]\n",
    "other_set = test_data[test_data['toxic'] == -1]\n",
    "\n",
    "print(\"training_set.shape:\", training_set.shape)\n",
    "print(\"test_set.shape:\", test_set.shape)\n",
    "print(\"other_set.shape:\", other_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "availability = cuda.is_available()\n",
    "if availability is True:\n",
    "    print(\"Device:\", cuda.get_device_name())\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il tokenizer e il modello preaddestrato di BERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased').to(\"cuda\")\n",
    "\n",
    "# L'espressione \"to('cuda')\" carica BertModel sulla GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_batches(dataset, batch_size):\n",
    "    return [dataset[i:i + batch_size] for i in range(0, len(dataset), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# METODO 1 DI ESTRAZIONE DI CARATTERISTICHE (MEDIA DELLE CARATTERISTICHE ESTRATTE DALL'ULTIMO LAYER)\n",
=======
>>>>>>> c8392bb066f907fa151a0a2ce9c1eca022ae90cc
    "def extract_features(strings):\n",
    "    inputs = tokenizer(strings, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "    # return_tensors=\"pt\": ritorna tensori PyTorch\n",
    "    # padding=True: frasi di lunghezza inferiore alla massima vengono adattate ad essa mediante del Padding\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    # Rappresentazione media e unidimensionale delle caratteristiche estratte\n",
    "    features = torch.mean(last_hidden_states, dim=1).squeeze()\n",
    "    to_return = features.cpu().numpy()\n",
    "    \n",
    "    del features\n",
    "    del outputs\n",
    "    del inputs\n",
    "    cuda.empty_cache()\n",
    "\n",
    "    return pd.DataFrame(to_return)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METODO 2 DI ESTRAZIONE DI CARATTERISTICHE BASATO SULL'EMBEDDING CORRISPONDENTE AL TOKEN CLS\n",
    "def extract_embeddings(texts):\n",
    "    # Tokenizza il testo\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "    # Passa i token al modello\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Estrai gli embeddings dall'ultimo layer del modello\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]  # Utilizza l'embedding corrispondente al token CLS\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> c8392bb066f907fa151a0a2ce9c1eca022ae90cc
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction for the Training Set...\n",
      "Batch to process: 153\n",
      "Extraction completed! Required Time: 0:06:16.127182\n",
      "X_train.shape: (30577, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Extraction for the Training Set...\")\n",
    "\n",
    "batches = split_to_batches(training_set['comment_text'].to_list(), batch_size=200)\n",
    "print(\"Batch to process:\", len(batches))\n",
    "\n",
    "dataframes = list()\n",
    "\n",
    "start = datetime.now()\n",
    "for batch in batches:\n",
    "    extraction = extract_features(batch)\n",
    "    dataframes.append(extraction)\n",
    "end = datetime.now()\n",
    "\n",
    "X_train = pd.concat(dataframes, axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Extraction completed! Required Time:\", str(end-start))\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "\n",
    "X_train.to_csv(\"./X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction for the Test Set...\n",
      "Batch to process: 320\n",
      "Extraction completed! Required Time: 0:12:55.694280\n",
      "X_test.shape: (63842, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Extraction for the Test Set...\")\n",
    "\n",
    "batches = split_to_batches(test_set['comment_text'].to_list(), batch_size=200)\n",
    "print(\"Batch to process:\", len(batches))\n",
    "\n",
    "dataframes = list()\n",
    "\n",
    "start = datetime.now()\n",
    "for batch in batches:\n",
    "    extraction = extract_features(batch)\n",
    "    dataframes.append(extraction)\n",
    "end = datetime.now()\n",
    "\n",
    "X_test = pd.concat(dataframes, axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Extraction completed! Required Time:\", str(end-start))\n",
    "print(\"X_test.shape:\", X_test.shape)\n",
    "\n",
    "X_test.to_csv(\"./X_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLProjectCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
