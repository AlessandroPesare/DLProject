{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier x Toxic Content Detection\n",
    "Il presente Notebook mostra l'addestramento ed il testing di un Classificatore basato su Support Vector Machine per il task\n",
    "di Toxic Content Detection.\n",
    "\n",
    "I dati sono stati processati come segue:\n",
    "1. Pulizia del testo (si veda, 'dataset_preprocessing.py')\n",
    "2. Lemmatizzazione con NLTK\n",
    "3. Vettorizzazione con TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento del Sistema\n",
    "Il Sistema è ovviamente riaddestrabile a piacere. Si consiglia, tuttavia, dato il tempo necessario per riaddestrare il classificatore, di utilizzare il file pickle 'svm_classifier' per eseguire subito gli esperimenti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento del training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey what is it talk what is it an exclusive gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bye dont look come or think of comming back to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you are gay or antisemmitian archangel white t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuck your filthy mother in the ass dry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30572</th>\n",
       "      <td>chris i dont know who you are talking to but i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30573</th>\n",
       "      <td>operation condor is also named a dirty war can...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30574</th>\n",
       "      <td>there is no evidence that this block has anyth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30575</th>\n",
       "      <td>thanks hey utkarshraj thanks for the kindness ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30576</th>\n",
       "      <td>from previous revision</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30577 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_text  toxic\n",
       "0           cocksucker before you piss around on my work      1\n",
       "1      hey what is it talk what is it an exclusive gr...      1\n",
       "2      bye dont look come or think of comming back to...      1\n",
       "3      you are gay or antisemmitian archangel white t...      1\n",
       "4                 fuck your filthy mother in the ass dry      1\n",
       "...                                                  ...    ...\n",
       "30572  chris i dont know who you are talking to but i...      0\n",
       "30573  operation condor is also named a dirty war can...      0\n",
       "30574  there is no evidence that this block has anyth...      0\n",
       "30575  thanks hey utkarshraj thanks for the kindness ...      0\n",
       "30576                             from previous revision      0\n",
       "\n",
       "[30577 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_csv(\"./../../datasets/training_set.csv\")\n",
    "training_set_lem = pd.read_csv(\"./../../datasets/training_set_lemmatized.csv\")\n",
    "\n",
    "# Osservazione: il Training Set è stato già ripulito\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sia l'addestramento che il testing saranno eseguiti sia sul Dataset \"non-lemmatizzato\" che sul Dataset \"lemmatizzato\". Osserviamo immediatamente che lo spazio delle feature del Dataset \"lemmatizzato\" è inferiore (49188 $<$ 56091) rispetto a quello del Dataset \"non-lemmatizzato\". Ciò ha impatto sia sul tempo necessario per addestrare il classificatore sia sull'accuracy del modello, come verrà mostrato in seguito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (30577, 56091)\n",
      "y_train.shape: (30577,)\n",
      "X_train_lem.shape: (30577, 49188)\n",
      "y_train_lem.shape: (30577,)\n"
     ]
    }
   ],
   "source": [
    "# Vettorizzazione con TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer_lem = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(training_set['comment_text'])\n",
    "y_train = training_set['toxic']\n",
    "\n",
    "X_train_lem = vectorizer_lem.fit_transform(training_set_lem['comment_text'])\n",
    "y_train_lem = training_set_lem['toxic']\n",
    "\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "print(\"y_train.shape: \" + str(y_train.shape))\n",
    "\n",
    "print(\"X_train_lem.shape: \" + str(X_train_lem.shape))\n",
    "print(\"y_train_lem.shape: \" + str(y_train_lem.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addestramento del Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "import pickle\n",
    "model_filename = 'svm_classifier.pkl'\n",
    "model_lem_filename = 'svm_classifier_lem.pkl'\n",
    "cl, cl_lem = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started on not-Lemmatized Dataset...\n",
      "Training completed! Required time: 0:03:21.515343\n"
     ]
    }
   ],
   "source": [
    "print(\"Training started on not-Lemmatized Dataset...\")\n",
    "#Create a svm Classifier\n",
    "clf = SVC(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "start = datetime.now()\n",
    "clf.fit(X_train, y_train)\n",
    "end = datetime.now()\n",
    "print(\"Training completed! Required time: \" + str(end-start))\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(cl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started on Lemmatized Dataset...\n",
      "Training completed! Required time: 0:06:28.751011\n"
     ]
    }
   ],
   "source": [
    "print(\"Training started on Lemmatized Dataset...\")\n",
    "#Create a svm Classifier\n",
    "clf_lem = SVC(kernel='poly')\n",
    "#Train the model using the training sets\n",
    "start = datetime.now()\n",
    "clf_lem.fit(X_train_lem, y_train_lem)\n",
    "end = datetime.now()\n",
    "print(\"Training completed! Required time: \" + str(end-start))\n",
    "with open(model_lem_filename, 'wb') as f:\n",
    "    pickle.dump(cl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_filename, 'rb') as f:\n",
    "    cl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_lem_filename, 'rb') as f:\n",
    "    cl_lem = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing del Sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"./../../datasets/test_set.csv\")\n",
    "test_set_lem = pd.read_csv(\"./../../datasets/test_set_lemmatized.csv\")\n",
    "\n",
    "test_set.dropna(inplace=True)\n",
    "test_set_lem.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set[test_set['toxic'] != -1]\n",
    "other_set = test_set[test_set['toxic'] == -1]\n",
    "\n",
    "test_set_lem = test_set_lem[test_set_lem['toxic'] != -1]\n",
    "other_set_lem = test_set_lem[test_set_lem['toxic'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape: (63842, 56091)\n",
      "y_test.shape: (63842,)\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(test_set['comment_text'])\n",
    "y_test = test_set['toxic']\n",
    "\n",
    "print(\"X_test.shape: \" + str(X_test.shape))\n",
    "print(\"y_test.shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_lem.shape: (63842, 49188)\n",
      "y_test_lem.shape: (63842,)\n"
     ]
    }
   ],
   "source": [
    "X_test_lem = vectorizer_lem.transform(test_set_lem['comment_text'])\n",
    "y_test_lem = test_set_lem['toxic']\n",
    "\n",
    "print(\"X_test_lem.shape: \" + str(X_test_lem.shape))\n",
    "print(\"y_test_lem.shape: \" + str(y_test_lem.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8520253124902102\n",
      "Precision: 0.3845995329028713\n",
      "Recall: 0.9198291440775423\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8432066664578177\n",
      "Precision: 0.3632243218743463\n",
      "Recall: 0.8557581731559061\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = clf_lem.predict(X_test_lem)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
